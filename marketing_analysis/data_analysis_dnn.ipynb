{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pb580\\anaconda3\\envs\\ML_Env\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\pb580\\anaconda3\\envs\\ML_Env\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SEQUENCE_LENGTH = 15\n",
    "EMBEDING_DIM = 20\n",
    "LABEL_NUM = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>grass_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subject_line_length</th>\n",
       "      <th>last_open_day</th>\n",
       "      <th>last_login_day</th>\n",
       "      <th>last_checkout_day</th>\n",
       "      <th>open_count_last_10_days</th>\n",
       "      <th>open_count_last_30_days</th>\n",
       "      <th>open_count_last_60_days</th>\n",
       "      <th>login_count_last_10_days</th>\n",
       "      <th>login_count_last_30_days</th>\n",
       "      <th>login_count_last_60_days</th>\n",
       "      <th>checkout_count_last_10_days</th>\n",
       "      <th>checkout_count_last_30_days</th>\n",
       "      <th>checkout_count_last_60_days</th>\n",
       "      <th>open_flag</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35471</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-08 00:00:00+08:00</td>\n",
       "      <td>78301</td>\n",
       "      <td>52</td>\n",
       "      <td>Never open</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>35471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45593</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-16 00:00:00+08:00</td>\n",
       "      <td>42464</td>\n",
       "      <td>47</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>121</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>45593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72737</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-02 00:00:00+08:00</td>\n",
       "      <td>103134</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39634</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-12 00:00:00+08:00</td>\n",
       "      <td>9922</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26078</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-03 00:00:00+08:00</td>\n",
       "      <td>76124</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22328</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-30 00:00:00+08:00</td>\n",
       "      <td>79392</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>22328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56906</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-08-23 00:00:00+08:00</td>\n",
       "      <td>40116</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-17 00:00:00+08:00</td>\n",
       "      <td>70926</td>\n",
       "      <td>30</td>\n",
       "      <td>Never open</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70205</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-09-02 00:00:00+08:00</td>\n",
       "      <td>13393</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>70205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-21 00:00:00+08:00</td>\n",
       "      <td>102038</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country_code                 grass_date  user_id  subject_line_length  \\\n",
       "35471             3  2019-08-08 00:00:00+08:00    78301                   52   \n",
       "45593             1  2019-08-16 00:00:00+08:00    42464                   47   \n",
       "72737             2  2019-09-02 00:00:00+08:00   103134                   38   \n",
       "39634             1  2019-08-12 00:00:00+08:00     9922                   30   \n",
       "26078             2  2019-08-03 00:00:00+08:00    76124                   34   \n",
       "22328             1  2019-07-30 00:00:00+08:00    79392                   60   \n",
       "56906             5  2019-08-23 00:00:00+08:00    40116                   20   \n",
       "3278              3  2019-07-17 00:00:00+08:00    70926                   30   \n",
       "70205             5  2019-09-02 00:00:00+08:00    13393                   23   \n",
       "7842              3  2019-07-21 00:00:00+08:00   102038                   50   \n",
       "\n",
       "      last_open_day last_login_day last_checkout_day  open_count_last_10_days  \\\n",
       "35471    Never open              1                 1                        0   \n",
       "45593           115              4                 6                        0   \n",
       "72737            12            129               129                        0   \n",
       "39634            48              2                10                        0   \n",
       "26078             1              5                38                        5   \n",
       "22328            66              2                 3                        0   \n",
       "56906             2              1                 4                        3   \n",
       "3278     Never open              7                15                        0   \n",
       "70205             8             14                20                        2   \n",
       "7842             23             17                23                        0   \n",
       "\n",
       "       open_count_last_30_days  open_count_last_60_days  \\\n",
       "35471                        0                        0   \n",
       "45593                        0                        0   \n",
       "72737                        1                        3   \n",
       "39634                        0                        1   \n",
       "26078                       14                       29   \n",
       "22328                        0                        0   \n",
       "56906                       11                       17   \n",
       "3278                         0                        0   \n",
       "70205                        4                       13   \n",
       "7842                         1                        2   \n",
       "\n",
       "       login_count_last_10_days  login_count_last_30_days  \\\n",
       "35471                        11                        33   \n",
       "45593                        68                       121   \n",
       "72737                         0                         0   \n",
       "39634                         8                        14   \n",
       "26078                         3                         9   \n",
       "22328                        36                        77   \n",
       "56906                        10                        10   \n",
       "3278                          9                        28   \n",
       "70205                         0                        10   \n",
       "7842                          0                         7   \n",
       "\n",
       "       login_count_last_60_days  checkout_count_last_10_days  \\\n",
       "35471                        72                            3   \n",
       "45593                       220                            1   \n",
       "72737                         0                            0   \n",
       "39634                        20                            1   \n",
       "26078                        27                            0   \n",
       "22328                        94                           15   \n",
       "56906                        13                            1   \n",
       "3278                         34                            0   \n",
       "70205                        18                            0   \n",
       "7842                         16                            0   \n",
       "\n",
       "       checkout_count_last_30_days  checkout_count_last_60_days  open_flag  \\\n",
       "35471                            5                            8          1   \n",
       "45593                            3                            5          0   \n",
       "72737                            0                            0          0   \n",
       "39634                            2                            3          0   \n",
       "26078                            0                            1          1   \n",
       "22328                           24                           29          0   \n",
       "56906                            1                            1          1   \n",
       "3278                             6                            7          0   \n",
       "70205                            1                            2          1   \n",
       "7842                             1                            5          0   \n",
       "\n",
       "       row_id  \n",
       "35471   35471  \n",
       "45593   45593  \n",
       "72737   72737  \n",
       "39634   39634  \n",
       "26078   26078  \n",
       "22328   22328  \n",
       "56906   56906  \n",
       "3278     3278  \n",
       "70205   70205  \n",
       "7842     7842  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train = pd.read_csv(src)\n",
    "_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = _train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data and labels into machine-recognizable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train.drop(['user_id', 'open_flag', 'row_id'], axis=1, inplace=False).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace('Never open', -1).replace('Never login', -1).replace('Never checkout', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_timestamp(datetime):\n",
    "    return datetime.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.563206e+09\n",
       "1        1.563206e+09\n",
       "2        1.563206e+09\n",
       "3        1.563206e+09\n",
       "4        1.563206e+09\n",
       "             ...     \n",
       "73534    1.567354e+09\n",
       "73535    1.567354e+09\n",
       "73536    1.567354e+09\n",
       "73537    1.567354e+09\n",
       "73538    1.567354e+09\n",
       "Name: grass_date, Length: 73539, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform datetime to unit(s)\n",
    "train['grass_date'] = pd.to_datetime(train['grass_date'])\n",
    "train['grass_date'] = train['grass_date'].apply(to_timestamp)\n",
    "train['grass_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73539/73539 [00:47<00:00, 1548.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87560055 -1.68865218  0.03062836 -0.19343485 -0.13677297 -0.32661951\n",
      "  -0.51984502 -0.17077048 -0.12899651  0.26948899  0.46802047  0.69605094\n",
      "  -0.31512753  0.28674948  0.32754016]\n",
      " [ 0.87560055 -1.68865218  0.03062836 -0.3811885  -0.1425771  -0.41148591\n",
      "   0.62037966  1.36088847  1.51610264  0.71643819  0.60011063  0.57073563\n",
      "   0.03120522 -0.23367649 -0.10164174]\n",
      " [ 2.06945961 -1.68865218  0.47629107 -0.28731167 -0.13967503 -0.43694583\n",
      "  -0.51984502  0.26684636  0.8833722   1.16338738  1.15488933  0.9745294\n",
      "   1.41653622  2.10824036  1.54355553]\n",
      " [-0.91518805 -1.68865218  0.47629107  0.36982611 -0.12806678 -0.02958709\n",
      "  -0.51984502 -0.60838733 -0.50863478  0.04601439 -0.0603402   0.27833324\n",
      "   0.03120522  0.02653649  0.04141889]\n",
      " [ 2.06945961 -1.68865218  0.47629107  3.7118411  -0.13677297  1.39616852\n",
      "  -0.51984502 -0.60838733 -0.63518087 -0.47542634 -0.5358648  -0.61279785\n",
      "  -0.31512753 -0.36378298 -0.387763  ]]\n",
      "[0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "_inputs = list(list(train.loc[i, columns]) for i in tqdm(range(len(train))))\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(_inputs)\n",
    "_inputs = std_scaler.transform(_inputs)\n",
    "_labels = train['open_flag'].tolist()\n",
    "print(_inputs[:5])\n",
    "print(_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.asarray(_inputs, dtype='int32')\n",
    "_labels = np.asarray(_labels, dtype='int32')\n",
    "labels = to_categorical(_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random partial data selection\n",
    "<span style=\"color:#FF0000\"><i class=\"fa fa-exclamation-circle\"></i>\n",
    " To fit the whole data, please skip this cell</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58831\n",
      "14708\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2)\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Dense(units=16, input_dim=15, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name='accuracy')])\n",
    "model.summary()\n",
    "cp = ModelCheckpoint('model/model_dnn_test.hdf5',monitor='val_accuracy',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1823/1839 [============================>.] - ETA: 0s - loss: 0.3569 - accuracy: 0.8711\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87565, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 6s 3ms/step - loss: 0.3565 - accuracy: 0.8712 - val_loss: 0.3385 - val_accuracy: 0.8756\n",
      "Epoch 2/100\n",
      "1821/1839 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.8775\n",
      "Epoch 00002: val_accuracy did not improve from 0.87565\n",
      "1839/1839 [==============================] - 6s 3ms/step - loss: 0.3323 - accuracy: 0.8774 - val_loss: 0.3381 - val_accuracy: 0.8755\n",
      "Epoch 3/100\n",
      "1832/1839 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.8778\n",
      "Epoch 00003: val_accuracy did not improve from 0.87565\n",
      "1839/1839 [==============================] - 6s 3ms/step - loss: 0.3305 - accuracy: 0.8779 - val_loss: 0.3370 - val_accuracy: 0.8755\n",
      "Epoch 4/100\n",
      "1829/1839 [============================>.] - ETA: 0s - loss: 0.3297 - accuracy: 0.8780\n",
      "Epoch 00004: val_accuracy improved from 0.87565 to 0.87571, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 6s 3ms/step - loss: 0.3297 - accuracy: 0.8780 - val_loss: 0.3360 - val_accuracy: 0.8757\n",
      "Epoch 5/100\n",
      "1824/1839 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.8786\n",
      "Epoch 00005: val_accuracy improved from 0.87571 to 0.87639, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 6s 3ms/step - loss: 0.3291 - accuracy: 0.8785 - val_loss: 0.3356 - val_accuracy: 0.8764\n",
      "Epoch 6/100\n",
      "1836/1839 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.8783\n",
      "Epoch 00006: val_accuracy did not improve from 0.87639\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3291 - accuracy: 0.8784 - val_loss: 0.3361 - val_accuracy: 0.8763\n",
      "Epoch 7/100\n",
      "1835/1839 [============================>.] - ETA: 0s - loss: 0.3285 - accuracy: 0.8788\n",
      "Epoch 00007: val_accuracy did not improve from 0.87639\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3285 - accuracy: 0.8789 - val_loss: 0.3357 - val_accuracy: 0.8763\n",
      "Epoch 8/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3284 - accuracy: 0.8785\n",
      "Epoch 00008: val_accuracy improved from 0.87639 to 0.87680, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3283 - accuracy: 0.8785 - val_loss: 0.3365 - val_accuracy: 0.8768\n",
      "Epoch 9/100\n",
      "1836/1839 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8792\n",
      "Epoch 00009: val_accuracy did not improve from 0.87680\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3282 - accuracy: 0.8791 - val_loss: 0.3361 - val_accuracy: 0.8763\n",
      "Epoch 10/100\n",
      "1839/1839 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8791\n",
      "Epoch 00010: val_accuracy improved from 0.87680 to 0.87721, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3281 - accuracy: 0.8791 - val_loss: 0.3355 - val_accuracy: 0.8772\n",
      "Epoch 11/100\n",
      "1835/1839 [============================>.] - ETA: 0s - loss: 0.3280 - accuracy: 0.8788\n",
      "Epoch 00011: val_accuracy did not improve from 0.87721\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3281 - accuracy: 0.8788 - val_loss: 0.3349 - val_accuracy: 0.8771\n",
      "Epoch 12/100\n",
      "1838/1839 [============================>.] - ETA: 0s - loss: 0.3275 - accuracy: 0.8792\n",
      "Epoch 00012: val_accuracy improved from 0.87721 to 0.87728, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3276 - accuracy: 0.8791 - val_loss: 0.3353 - val_accuracy: 0.8773\n",
      "Epoch 13/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.8788\n",
      "Epoch 00013: val_accuracy did not improve from 0.87728\n",
      "1839/1839 [==============================] - 8s 5ms/step - loss: 0.3278 - accuracy: 0.8788 - val_loss: 0.3353 - val_accuracy: 0.8770\n",
      "Epoch 14/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8788\n",
      "Epoch 00014: val_accuracy improved from 0.87728 to 0.87741, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 8s 5ms/step - loss: 0.3276 - accuracy: 0.8789 - val_loss: 0.3348 - val_accuracy: 0.8774\n",
      "Epoch 15/100\n",
      "1831/1839 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.8790\n",
      "Epoch 00015: val_accuracy did not improve from 0.87741\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3274 - accuracy: 0.8790 - val_loss: 0.3352 - val_accuracy: 0.8771\n",
      "Epoch 16/100\n",
      "1837/1839 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.8791\n",
      "Epoch 00016: val_accuracy did not improve from 0.87741\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3273 - accuracy: 0.8791 - val_loss: 0.3350 - val_accuracy: 0.8774\n",
      "Epoch 17/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.8793\n",
      "Epoch 00017: val_accuracy did not improve from 0.87741\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3271 - accuracy: 0.8792 - val_loss: 0.3369 - val_accuracy: 0.8761\n",
      "Epoch 18/100\n",
      "1837/1839 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.8789\n",
      "Epoch 00018: val_accuracy did not improve from 0.87741\n",
      "1839/1839 [==============================] - 8s 5ms/step - loss: 0.3272 - accuracy: 0.8789 - val_loss: 0.3349 - val_accuracy: 0.8773\n",
      "Epoch 19/100\n",
      "1839/1839 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.8790\n",
      "Epoch 00019: val_accuracy did not improve from 0.87741\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3271 - accuracy: 0.8790 - val_loss: 0.3346 - val_accuracy: 0.8773\n",
      "Epoch 20/100\n",
      "1836/1839 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.8793\n",
      "Epoch 00020: val_accuracy improved from 0.87741 to 0.87755, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 10s 6ms/step - loss: 0.3269 - accuracy: 0.8793 - val_loss: 0.3349 - val_accuracy: 0.8775\n",
      "Epoch 21/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3270 - accuracy: 0.8793\n",
      "Epoch 00021: val_accuracy improved from 0.87755 to 0.87762, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 8s 5ms/step - loss: 0.3269 - accuracy: 0.8794 - val_loss: 0.3352 - val_accuracy: 0.8776\n",
      "Epoch 22/100\n",
      "1831/1839 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.8795\n",
      "Epoch 00022: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3268 - accuracy: 0.8796 - val_loss: 0.3342 - val_accuracy: 0.8773\n",
      "Epoch 23/100\n",
      "1837/1839 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.8793\n",
      "Epoch 00023: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 10s 5ms/step - loss: 0.3266 - accuracy: 0.8793 - val_loss: 0.3352 - val_accuracy: 0.8773\n",
      "Epoch 24/100\n",
      "1832/1839 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8794\n",
      "Epoch 00024: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3264 - accuracy: 0.8793 - val_loss: 0.3347 - val_accuracy: 0.8771\n",
      "Epoch 25/100\n",
      "1835/1839 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.8796\n",
      "Epoch 00025: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 10s 5ms/step - loss: 0.3266 - accuracy: 0.8795 - val_loss: 0.3343 - val_accuracy: 0.8774\n",
      "Epoch 26/100\n",
      "1824/1839 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.8796\n",
      "Epoch 00026: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3264 - accuracy: 0.8797 - val_loss: 0.3350 - val_accuracy: 0.8774\n",
      "Epoch 27/100\n",
      "1834/1839 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.8793\n",
      "Epoch 00027: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3264 - accuracy: 0.8793 - val_loss: 0.3355 - val_accuracy: 0.8771\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836/1839 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8797\n",
      "Epoch 00028: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3263 - accuracy: 0.8797 - val_loss: 0.3341 - val_accuracy: 0.8776\n",
      "Epoch 29/100\n",
      "1829/1839 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.8792\n",
      "Epoch 00029: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 11s 6ms/step - loss: 0.3262 - accuracy: 0.8792 - val_loss: 0.3356 - val_accuracy: 0.8773\n",
      "Epoch 30/100\n",
      "1832/1839 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8795\n",
      "Epoch 00030: val_accuracy did not improve from 0.87762\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3262 - accuracy: 0.8796 - val_loss: 0.3343 - val_accuracy: 0.8775\n",
      "Epoch 31/100\n",
      "1835/1839 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.8796\n",
      "Epoch 00031: val_accuracy improved from 0.87762 to 0.87803, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3261 - accuracy: 0.8796 - val_loss: 0.3345 - val_accuracy: 0.8780\n",
      "Epoch 32/100\n",
      "1839/1839 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.8795\n",
      "Epoch 00032: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3259 - accuracy: 0.8795 - val_loss: 0.3341 - val_accuracy: 0.8772\n",
      "Epoch 33/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.8795\n",
      "Epoch 00033: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 11s 6ms/step - loss: 0.3257 - accuracy: 0.8795 - val_loss: 0.3346 - val_accuracy: 0.8769\n",
      "Epoch 34/100\n",
      "1837/1839 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.8797\n",
      "Epoch 00034: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 19s 10ms/step - loss: 0.3259 - accuracy: 0.8797 - val_loss: 0.3347 - val_accuracy: 0.8778\n",
      "Epoch 35/100\n",
      "1828/1839 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.8796\n",
      "Epoch 00035: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 10s 5ms/step - loss: 0.3258 - accuracy: 0.8796 - val_loss: 0.3348 - val_accuracy: 0.8771\n",
      "Epoch 36/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8799\n",
      "Epoch 00036: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 10s 5ms/step - loss: 0.3257 - accuracy: 0.8799 - val_loss: 0.3344 - val_accuracy: 0.8773\n",
      "Epoch 37/100\n",
      "1837/1839 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8800\n",
      "Epoch 00037: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 14s 8ms/step - loss: 0.3255 - accuracy: 0.8800 - val_loss: 0.3346 - val_accuracy: 0.8773\n",
      "Epoch 38/100\n",
      "1830/1839 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8800\n",
      "Epoch 00038: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 11s 6ms/step - loss: 0.3255 - accuracy: 0.8800 - val_loss: 0.3341 - val_accuracy: 0.8779\n",
      "Epoch 39/100\n",
      "1822/1839 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8794\n",
      "Epoch 00039: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3256 - accuracy: 0.8794 - val_loss: 0.3345 - val_accuracy: 0.8775\n",
      "Epoch 40/100\n",
      "1823/1839 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8803\n",
      "Epoch 00040: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 7s 4ms/step - loss: 0.3253 - accuracy: 0.8801 - val_loss: 0.3343 - val_accuracy: 0.8775\n",
      "Epoch 41/100\n",
      "1831/1839 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8799\n",
      "Epoch 00041: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3254 - accuracy: 0.8798 - val_loss: 0.3352 - val_accuracy: 0.8778\n",
      "Epoch 42/100\n",
      "1828/1839 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8798\n",
      "Epoch 00042: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3253 - accuracy: 0.8799 - val_loss: 0.3372 - val_accuracy: 0.8764\n",
      "Epoch 43/100\n",
      "1829/1839 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8799\n",
      "Epoch 00043: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3253 - accuracy: 0.8798 - val_loss: 0.3347 - val_accuracy: 0.8778\n",
      "Epoch 44/100\n",
      "1829/1839 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8798\n",
      "Epoch 00044: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 8s 4ms/step - loss: 0.3253 - accuracy: 0.8799 - val_loss: 0.3366 - val_accuracy: 0.8760\n",
      "Epoch 45/100\n",
      "1831/1839 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.8798\n",
      "Epoch 00045: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 11s 6ms/step - loss: 0.3251 - accuracy: 0.8797 - val_loss: 0.3352 - val_accuracy: 0.8773\n",
      "Epoch 46/100\n",
      "1834/1839 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8798\n",
      "Epoch 00046: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 10s 5ms/step - loss: 0.3254 - accuracy: 0.8799 - val_loss: 0.3345 - val_accuracy: 0.8777\n",
      "Epoch 47/100\n",
      "1832/1839 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.8801\n",
      "Epoch 00047: val_accuracy did not improve from 0.87803\n",
      "1839/1839 [==============================] - 10s 6ms/step - loss: 0.3252 - accuracy: 0.8801 - val_loss: 0.3353 - val_accuracy: 0.8777\n",
      "Epoch 48/100\n",
      "1832/1839 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8803\n",
      "Epoch 00048: val_accuracy improved from 0.87803 to 0.87843, saving model to model/model_dnn_test.hdf5\n",
      "1839/1839 [==============================] - 10s 5ms/step - loss: 0.3252 - accuracy: 0.8803 - val_loss: 0.3346 - val_accuracy: 0.8784\n",
      "Epoch 49/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8794\n",
      "Epoch 00049: val_accuracy did not improve from 0.87843\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3251 - accuracy: 0.8795 - val_loss: 0.3345 - val_accuracy: 0.8778\n",
      "Epoch 50/100\n",
      "1839/1839 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8803\n",
      "Epoch 00050: val_accuracy did not improve from 0.87843\n",
      "1839/1839 [==============================] - 8s 5ms/step - loss: 0.3250 - accuracy: 0.8803 - val_loss: 0.3351 - val_accuracy: 0.8769\n",
      "Epoch 51/100\n",
      "1833/1839 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.8801\n",
      "Epoch 00051: val_accuracy did not improve from 0.87843\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3248 - accuracy: 0.8802 - val_loss: 0.3342 - val_accuracy: 0.8783\n",
      "Epoch 52/100\n",
      "1838/1839 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.8798\n",
      "Epoch 00052: val_accuracy did not improve from 0.87843\n",
      "1839/1839 [==============================] - 9s 5ms/step - loss: 0.3249 - accuracy: 0.8798 - val_loss: 0.3341 - val_accuracy: 0.8778\n",
      "Epoch 53/100\n",
      "1836/1839 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8799"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ccbcbcfeeda7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1079\u001b[0m                 step_num=step):\n\u001b[0;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_accuracy = history.history['accuracy']\n",
    "h_val_accuracy = history.history['val_accuracy']\n",
    "h_loss = history.history['loss']\n",
    "h_val_loss = history.history['val_loss']\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "fig.add_trace(go.Scatter(y=h_accuracy, mode='lines+markers', name='accuracy', line=dict(color='skyblue')),\n",
    "              row=1, col=1)\n",
    "fig.add_trace(go.Scatter(y=h_val_accuracy, mode='lines+markers', name='validation accuracy', line=dict(color='dodgerblue')),\n",
    "              row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(y=h_loss, mode='lines+markers',name='loss', line=dict(color='lightsalmon')),\n",
    "              row=1, col=2)\n",
    "fig.add_trace(go.Scatter(y=h_val_loss, mode='lines+markers', name='validation loss', line=dict(color='tomato')),\n",
    "              row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text='Epochs', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Epochs', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Accuracy', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Loss', row=1, col=2)\n",
    "\n",
    "fig.update_layout(title='Model Performation', height=480, width=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prediction\n",
    "I don't know why the test data on kaggle is different with the one on google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('data/test.csv')\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testdf['review'].tolist()\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "test_seq = pad_sequences(test_seq, padding='post', maxlen=WORD_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.argmax(pred, axis=1)\n",
    "classes = classes + 1\n",
    "submission = testdf.drop('review', axis=1)\n",
    "submission['rating']=classes\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===========Description===========\\n', submission.describe(), '\\n')\n",
    "print('rating 1: ', submission[submission['rating'] == 1].rating.count())\n",
    "print('rating 2: ', submission[submission['rating'] == 2].rating.count())\n",
    "print('rating 3: ', submission[submission['rating'] == 3].rating.count())\n",
    "print('rating 4: ', submission[submission['rating'] == 4].rating.count())\n",
    "print('rating 5: ', submission[submission['rating'] == 5].rating.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission/submission_00.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
