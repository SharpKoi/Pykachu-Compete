{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = 'data/cleaned_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initially clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower().str.strip().str.replace(u'\\u200b', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good quality\n",
    "gqdf = df[df['review'] == 'good quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexlist = list(gqdf.index)\n",
    "for i in indexlist:\n",
    "    df.rating.loc[i] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji Transformation\n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widen_emoji(text):\n",
    "    for c in text:\n",
    "        if c in emoji.UNICODE_EMOJI.keys():\n",
    "            text = ' '.join(text.replace(c, (' '+c+' ')).split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(widen_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查一下是否轉換成功\n",
    "emoji_df = df[df['review'].str.contains(u'[\\U00002600-\\U000027BF]|[\\U0001f300-\\U0001f64F]|[\\U0001f680-\\U0001f6FF]')]\n",
    "print(len(emoji_df))\n",
    "emoji_df.sample(5)['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用空白分開emoji後的資料\n",
    "df.to_csv('data/cleaned_data/data_emoji.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(emojis.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用空白分開emoji且把emoji轉成單詞後的資料\n",
    "df.to_csv('data/cleaned_data/data_emoji2word.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contractions Decompose\n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查含有 xx'xx 的review\n",
    "def check_abbr():\n",
    "    abbr_pat = re.compile(r'[\\w]+\\'[\\w]+')\n",
    "    return df[df['review'].str.contains(abbr_pat)]\n",
    "\n",
    "abbr_df = check_abbr()\n",
    "print(len(abbr_df))\n",
    "abbr_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'\\'s': ' ', '\\'m': ' am', '\\'re': ' are', '\\'ll': ' will', '\\'d': ' would', '\\'t': ' not', '\\'ve': ' have'}\n",
    "\n",
    "for abbr in mapping.keys():\n",
    "    df['review'] = df['review'].str.replace(abbr, mapping[abbr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剩下的很多都是打錯或印尼後綴詞 不管了\n",
    "df['review'] = df['review'].str.replace('\\'', '').str.replace('oclock', 'o\\'clock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/cleaned_data/data_sol24.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向1  \n",
    "I have no idea.... \n",
    "交給 JiaLing 了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sol1 import trim_letters, detect_language, spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"([a-zA-z_])\\1{2,}\", re.DOTALL)\n",
    "df[df['review'].str.match(pattern)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(trim_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"([a-zA-z_])\\1\", re.DOTALL)\n",
    "df[df['review'].str.match(pattern)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 印尼單詞轉英文\n",
    "id2en = {'bagus': 'very good', 'bgus': 'very good', \n",
    "         'banget': 'really', 'bnget': 'really', \n",
    "         'sip': 'ok', 'siip': 'ok', 'ssiipp':'ok',\n",
    "         'baunya': 'smell', \n",
    "         'pesenan': 'purchase'}\n",
    "\n",
    "for idon in id2en.keys():\n",
    "    df['review'] = df['review'].str.replace(idon, id2en[idon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 縮寫轉換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼字糾正\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dest+'data_sol241.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meaningless Spelling Filter\n",
    "<span style='color:#FF0000'><i class=\"fa fa-exclamation-circle\"></i> 這個cell必須建立在方向2、4、1都解決的前提下才能執行。</span>  \n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向5  \n",
    "過濾掉那些亂打字的字串，目前的做法是詞頻小於n個的都拿掉，可能會拿掉一些正常單詞，但出現數量太少也不會影響學習。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords') 沒下載過的話把註解拿掉\n",
    "# nltk.download('punkt') 沒下載過的話把註解拿掉\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取處理好的檔\n",
    "df = pd.read_csv(dest+'data_sol241.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['review'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先把符號過濾掉\n",
    "df['review'] = df['review'].str.replace(r'[^\\w\\s\\r\\n]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義最小詞頻(3就有很強的效果了，4以上明顯會過濾掉有意義單詞)\n",
    "TOL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有單詞丟進words\n",
    "words = []\n",
    "stops = stopwords.words('english') + list(string.punctuation)\n",
    "wordslist = df['review'].apply(nltk.word_tokenize)\n",
    "for i in range(len(df)):\n",
    "    words.extend([word for word in wordslist[i] if word not in stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計每個單詞出現的量(詞頻)\n",
    "wordfreqs = nltk.FreqDist(words)\n",
    "wordfreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 看一下哪些東西可以刪\n",
    "def get_meanless_words(tolerance=3, maxlen=10):\n",
    "    removables = {}\n",
    "    wordfreq_arr = np.array(list(wordfreqs.items()))\n",
    "    for wf in wordfreq_arr:\n",
    "        if (int(wf[1]) <= tolerance) and (len(wf[0]) >= maxlen):\n",
    "            removables[wf[0]] = wf[1]\n",
    "\n",
    "    return removables\n",
    "\n",
    "meanless_words_dict = get_meanless_words(TOL, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meanless_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過濾掉無意義的詞，丟回df裡\n",
    "cleaned_texts = []\n",
    "meanless_words = list(meanless_words_dict.keys())\n",
    "for wl in wordslist:\n",
    "    cleaned_words = []\n",
    "    for w in wl:\n",
    "        if w not in meanless_words:\n",
    "            cleaned_words.append(w)\n",
    "    cleaned_texts.append(' '.join(cleaned_words))\n",
    "\n",
    "df['review'] = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['review'].str.match(r'^[\\s]+$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dest+'trainbest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Processing\n",
    "<i class=\"fa fa-exclamation-circle\"></i> 等所有的處理流程都定好後，也要對 `test.csv` 做同樣處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.initially_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['review'] = test['review'].apply(pipline.emoji_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pipline.contractions_decompose(test, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>great danger, cool, motif and cantik2 jg models. delivery cepet. tp packing less okay krn only wear clear plastic nerawang klihtan contents jd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>one of the shades don not fit well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>very comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fast delivery. product expiry is on dec 2022. product wrap properly. no damage on the item.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>it  sooooo cute! i like playing with the glitters better than browsing on my phone now. item was also deliered earlier than i expected. thank you seller! may you have more buyers to come. :blush: :blush: :blush:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  \\\n",
       "0  1           \n",
       "1  2           \n",
       "2  3           \n",
       "3  4           \n",
       "4  5           \n",
       "\n",
       "                                                                                                                                                                                                                review  \n",
       "0  great danger, cool, motif and cantik2 jg models. delivery cepet. tp packing less okay krn only wear clear plastic nerawang klihtan contents jd                                                                       \n",
       "1  one of the shades don not fit well                                                                                                                                                                                   \n",
       "2  very comfortable                                                                                                                                                                                                     \n",
       "3  fast delivery. product expiry is on dec 2022. product wrap properly. no damage on the item.                                                                                                                          \n",
       "4  it  sooooo cute! i like playing with the glitters better than browsing on my phone now. item was also deliered earlier than i expected. thank you seller! may you have more buyers to come. :blush: :blush: :blush:  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(dest+'test_sol24.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
