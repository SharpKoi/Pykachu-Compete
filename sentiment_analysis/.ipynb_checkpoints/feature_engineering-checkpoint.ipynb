{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = 'data/cleaned_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initially clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower().str.strip().str.replace(u'\\u200b', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good quality\n",
    "gqdf = df[df['review'] == 'good quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pb580\\anaconda3\\envs\\ML_Env\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "indexlist = list(gqdf.index)\n",
    "for i in indexlist:\n",
    "    df.rating.loc[i] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji Transformation\n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widen_emoji(text):\n",
    "    for c in text:\n",
    "        if c in emoji.UNICODE_EMOJI.keys():\n",
    "            text = ' '.join(text.replace(c, (' '+c+' ')).split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(widen_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查一下是否轉換成功\n",
    "emoji_df = df[df['review'].str.contains(u'[\\U00002600-\\U000027BF]|[\\U0001f300-\\U0001f64F]|[\\U0001f680-\\U0001f6FF]')]\n",
    "print(len(emoji_df))\n",
    "emoji_df.sample(5)['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用空白分開emoji後的資料\n",
    "df.to_csv('data/cleaned_data/data_emoji.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(emojis.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用空白分開emoji且把emoji轉成單詞後的資料\n",
    "df.to_csv('data/cleaned_data/data_emoji2word.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contractions Decompose\n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查含有 xx'xx 的review\n",
    "def check_abbr():\n",
    "    abbr_pat = re.compile(r'[\\w]+\\'[\\w]+')\n",
    "    return df[df['review'].str.contains(abbr_pat)]\n",
    "\n",
    "abbr_df = check_abbr()\n",
    "print(len(abbr_df))\n",
    "abbr_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'\\'s': ' ', '\\'m': ' am', '\\'re': ' are', '\\'ll': ' will', '\\'d': ' would', '\\'t': ' not', '\\'ve': ' have'}\n",
    "\n",
    "for abbr in mapping.keys():\n",
    "    df['review'] = df['review'].str.replace(abbr, mapping[abbr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剩下的很多都是打錯或印尼後綴詞 不管了\n",
    "df['review'] = df['review'].str.replace('\\'', '').str.replace('oclock', 'o\\'clock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/cleaned_data/data_sol24.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向1  \n",
    "I have no idea.... \n",
    "交給 JiaLing 了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sol1 import trim_letters, detect_language, spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"([a-zA-z_])\\1{2,}\", re.DOTALL)\n",
    "df[df['review'].str.match(pattern)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(trim_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"([a-zA-z_])\\1\", re.DOTALL)\n",
    "df[df['review'].str.match(pattern)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 印尼單詞轉英文\n",
    "id2en = {'bagus': 'very good', 'bgus': 'very good', \n",
    "         'banget': 'really', 'bnget': 'really', \n",
    "         'sip': 'ok', 'siip': 'ok', 'ssiipp':'ok',\n",
    "         'baunya': 'smell', \n",
    "         'pesenan': 'purchase'}\n",
    "\n",
    "for idon in id2en.keys():\n",
    "    df['review'] = df['review'].str.replace(idon, id2en[idon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 縮寫轉換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼字糾正\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dest+'data_sol241.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meaningless Spelling Filter\n",
    "<span style='color:#FF0000'><i class=\"fa fa-exclamation-circle\"></i> 這個cell必須建立在方向2、4、1都解決的前提下才能執行。</span>  \n",
    "<i class=\"fa fa-exclamation-circle\"></i> 方向5  \n",
    "過濾掉那些亂打字的字串，目前的做法是詞頻小於n個的都拿掉，可能會拿掉一些正常單詞，但出現數量太少也不會影響學習。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords') 沒下載過的話把註解拿掉\n",
    "# nltk.download('punkt') 沒下載過的話把註解拿掉\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取處理好的檔\n",
    "df = pd.read_csv(dest+'data_sol241.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['review'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先把符號過濾掉\n",
    "df['review'] = df['review'].str.replace(r'[^\\w\\s\\r\\n]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義最小詞頻(3就有很強的效果了，4以上明顯會過濾掉有意義單詞)\n",
    "TOL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有單詞丟進words\n",
    "words = []\n",
    "stops = stopwords.words('english') + list(string.punctuation)\n",
    "wordslist = df['review'].apply(nltk.word_tokenize)\n",
    "for i in range(len(df)):\n",
    "    words.extend([word for word in wordslist[i] if word not in stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計每個單詞出現的量(詞頻)\n",
    "wordfreqs = nltk.FreqDist(words)\n",
    "wordfreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 看一下哪些東西可以刪\n",
    "def get_meanless_words(tolerance=3, maxlen=10):\n",
    "    removables = {}\n",
    "    wordfreq_arr = np.array(list(wordfreqs.items()))\n",
    "    for wf in wordfreq_arr:\n",
    "        if (int(wf[1]) <= tolerance) and (len(wf[0]) >= maxlen):\n",
    "            removables[wf[0]] = wf[1]\n",
    "\n",
    "    return removables\n",
    "\n",
    "meanless_words_dict = get_meanless_words(TOL, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meanless_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過濾掉無意義的詞，丟回df裡\n",
    "cleaned_texts = []\n",
    "meanless_words = list(meanless_words_dict.keys())\n",
    "for wl in wordslist:\n",
    "    cleaned_words = []\n",
    "    for w in wl:\n",
    "        if w not in meanless_words:\n",
    "            cleaned_words.append(w)\n",
    "    cleaned_texts.append(' '.join(cleaned_words))\n",
    "\n",
    "df['review'] = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['review'].str.match(r'^[\\s]+$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dest+'trainbest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.initially_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['review'] = test['review'].apply(pipline.emoji_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
